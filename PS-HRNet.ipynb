{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super-resolution & re-ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "######################################################################\n",
    "# import\n",
    "# ------\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from math import sqrt\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import functools\n",
    "import torch._utils\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import torch\n",
    "import scipy.io\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import dataset as mydataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from data_loader import ImageDatasettrain\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from shutil import copyfile\n",
    "version =  torch.__version__\n",
    "from  double_samplers import RandomIdentitySampler\n",
    "from random_erasing import RandomErasing\n",
    "from torch.optim import lr_scheduler\n",
    "from triplet_loss import TripletLoss, CrossEntropyLabelSmooth\n",
    "\n",
    "try:\n",
    "    from apex.fp16_utils import *\n",
    "    from apex import amp, optimizers\n",
    "except ImportError: # will be 3.x series\n",
    "    print('This is not an error. If you want to use low precision, i.e., fp16, please install the apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0')\n",
    "\n",
    "\n",
    "BN_MOMENTUM = 0.1\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
    "        init.constant(m.bias.data, 0.0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal(m.weight.data, a=0, mode='fan_out')\n",
    "    elif classname.find('BatchNorm1d') != -1:\n",
    "        init.normal(m.weight.data, 1.0, 0.02)\n",
    "        init.constant(m.bias.data, 0.0)\n",
    "\n",
    "def weights_init_classifier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        init.normal(m.weight.data, std=0.001)\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "# Defines the new fc layer and classification layer\n",
    "# |--Linear--|--bn--|--relu--|--Linear--|\n",
    "class ClassBlock(nn.Module):\n",
    "    def __init__(self, input_dim, class_num, droprate, relu=False, bnorm=True, num_bottleneck=512, linear=True, return_f = False):\n",
    "        super(ClassBlock, self).__init__()\n",
    "        self.return_f = return_f\n",
    "        add_block = []\n",
    "        if linear:\n",
    "            add_block += [nn.Linear(input_dim, num_bottleneck)]\n",
    "        else:\n",
    "            num_bottleneck = input_dim\n",
    "        if bnorm:\n",
    "            add_block += [nn.BatchNorm1d(num_bottleneck)]\n",
    "        if relu:\n",
    "            add_block += [nn.LeakyReLU(0.1)]\n",
    "        if droprate>0:\n",
    "            add_block += [nn.Dropout(p=droprate)]\n",
    "        add_block = nn.Sequential(*add_block)\n",
    "        add_block.apply(weights_init_kaiming)\n",
    "\n",
    "        classifier = []\n",
    "        classifier += [nn.Linear(num_bottleneck, class_num)]\n",
    "        classifier = nn.Sequential(*classifier)\n",
    "        classifier.apply(weights_init_classifier)\n",
    "\n",
    "        self.add_block = add_block\n",
    "        self.classifier = classifier\n",
    "    def forward(self, x):\n",
    "        x = self.add_block(x)\n",
    "        if self.return_f:\n",
    "            f = x\n",
    "            x = self.classifier(x)\n",
    "            return x,f\n",
    "        else:\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "\n",
    "#######################################################################          \n",
    "# Channel Attention (CA) Layer\n",
    "# ------\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.module = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(64, 4, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4, 64, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.module(x)\n",
    "#######################################################################        \n",
    "# VDSR\n",
    "# ------\n",
    "\n",
    "class Conv_ReLU_Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv_ReLU_Block, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.ca = ChannelAttention()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.ca(self.conv(x)))\n",
    "    \n",
    "class VDSR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VDSR, self).__init__()\n",
    "        self.residual_layer = self.make_layer(Conv_ReLU_Block, 18)\n",
    "        self.input = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.output = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, sqrt(2. / n))\n",
    "                \n",
    "    def make_layer(self, block, num_of_layer):\n",
    "        layers = []\n",
    "        for _ in range(num_of_layer):\n",
    "            layers.append(block())\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.input(x))\n",
    "        out = self.residual_layer(out)\n",
    "        out = self.output(out)\n",
    "        out = torch.add(out,residual)\n",
    "        return out \n",
    "    \n",
    "#######################################################################        \n",
    "# HRNet\n",
    "# ------\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion,\n",
    "                               momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class HighResolutionModule(nn.Module):\n",
    "    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n",
    "                 num_channels, fuse_method, multi_scale_output=True):\n",
    "        super(HighResolutionModule, self).__init__()\n",
    "        self._check_branches(\n",
    "            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n",
    "\n",
    "        self.num_inchannels = num_inchannels\n",
    "        self.fuse_method = fuse_method\n",
    "        self.num_branches = num_branches\n",
    "\n",
    "        self.multi_scale_output = multi_scale_output\n",
    "\n",
    "        self.branches = self._make_branches(\n",
    "            num_branches, blocks, num_blocks, num_channels)\n",
    "        self.fuse_layers = self._make_fuse_layers()\n",
    "        self.relu = nn.ReLU(False)\n",
    "\n",
    "    def _check_branches(self, num_branches, blocks, num_blocks,\n",
    "                        num_inchannels, num_channels):\n",
    "        if num_branches != len(num_blocks):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(\n",
    "                num_branches, len(num_blocks))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_channels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(\n",
    "                num_branches, len(num_channels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        if num_branches != len(num_inchannels):\n",
    "            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(\n",
    "                num_branches, len(num_inchannels))\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,\n",
    "                         stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or \\\n",
    "           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.num_inchannels[branch_index],\n",
    "                          num_channels[branch_index] * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(num_channels[branch_index] * block.expansion,\n",
    "                            momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.num_inchannels[branch_index],\n",
    "                            num_channels[branch_index], stride, downsample))\n",
    "        self.num_inchannels[branch_index] = \\\n",
    "            num_channels[branch_index] * block.expansion\n",
    "        for i in range(1, num_blocks[branch_index]):\n",
    "            layers.append(block(self.num_inchannels[branch_index],\n",
    "                                num_channels[branch_index]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n",
    "        branches = []\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            branches.append(\n",
    "                self._make_one_branch(i, block, num_blocks, num_channels))\n",
    "\n",
    "        return nn.ModuleList(branches)\n",
    "\n",
    "    def _make_fuse_layers(self):\n",
    "        if self.num_branches == 1:\n",
    "            return None\n",
    "\n",
    "        num_branches = self.num_branches\n",
    "        num_inchannels = self.num_inchannels\n",
    "        fuse_layers = []\n",
    "        for i in range(num_branches if self.multi_scale_output else 1):\n",
    "            fuse_layer = []\n",
    "            for j in range(num_branches):\n",
    "                if j > i:\n",
    "                    fuse_layer.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_inchannels[j],\n",
    "                                  num_inchannels[i],\n",
    "                                  1,\n",
    "                                  1,\n",
    "                                  0,\n",
    "                                  bias=False),\n",
    "                        nn.BatchNorm2d(num_inchannels[i], \n",
    "                                       momentum=BN_MOMENTUM),\n",
    "                        nn.Upsample(scale_factor=2**(j-i), mode='nearest')))\n",
    "                elif j == i:\n",
    "                    fuse_layer.append(None)\n",
    "                else:\n",
    "                    conv3x3s = []\n",
    "                    for k in range(i-j):\n",
    "                        if k == i - j - 1:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[i]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j],\n",
    "                                          num_outchannels_conv3x3,\n",
    "                                          3, 2, 1, bias=False),\n",
    "                                nn.BatchNorm2d(num_outchannels_conv3x3, \n",
    "                                            momentum=BN_MOMENTUM)))\n",
    "                        else:\n",
    "                            num_outchannels_conv3x3 = num_inchannels[j]\n",
    "                            conv3x3s.append(nn.Sequential(\n",
    "                                nn.Conv2d(num_inchannels[j],\n",
    "                                          num_outchannels_conv3x3,\n",
    "                                          3, 2, 1, bias=False),\n",
    "                                nn.BatchNorm2d(num_outchannels_conv3x3,\n",
    "                                            momentum=BN_MOMENTUM),\n",
    "                                nn.ReLU(False)))\n",
    "                    fuse_layer.append(nn.Sequential(*conv3x3s))\n",
    "            fuse_layers.append(nn.ModuleList(fuse_layer))\n",
    "\n",
    "        return nn.ModuleList(fuse_layers)\n",
    "\n",
    "    def get_num_inchannels(self):\n",
    "        return self.num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_branches == 1:\n",
    "            return [self.branches[0](x[0])]\n",
    "\n",
    "        for i in range(self.num_branches):\n",
    "            x[i] = self.branches[i](x[i])\n",
    "\n",
    "        x_fuse = []\n",
    "        for i in range(len(self.fuse_layers)):\n",
    "            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n",
    "            for j in range(1, self.num_branches):\n",
    "                if i == j:\n",
    "                    y = y + x[j]\n",
    "                else:\n",
    "                    y = y + self.fuse_layers[i][j](x[j])\n",
    "            x_fuse.append(self.relu(y))\n",
    "\n",
    "        return x_fuse\n",
    "\n",
    "\n",
    "blocks_dict = {\n",
    "    'BASIC': BasicBlock,\n",
    "    'BOTTLENECK': Bottleneck\n",
    "}\n",
    "\n",
    "\n",
    "class HighResolutionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, cl, cfg, **kwargs):\n",
    "        super(HighResolutionNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.stage1_cfg = cfg['MODEL']['EXTRA']['STAGE1']\n",
    "        num_channels = self.stage1_cfg['NUM_CHANNELS'][0]\n",
    "        block = blocks_dict[self.stage1_cfg['BLOCK']]\n",
    "        num_blocks = self.stage1_cfg['NUM_BLOCKS'][0]\n",
    "        self.layer1 = self._make_layer(block, 64, num_channels, num_blocks)\n",
    "        stage1_out_channel = block.expansion*num_channels\n",
    "\n",
    "        self.stage2_cfg = cfg['MODEL']['EXTRA']['STAGE2']\n",
    "        num_channels = self.stage2_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage2_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition1 = self._make_transition_layer(\n",
    "            [stage1_out_channel], num_channels)\n",
    "        self.stage2, pre_stage_channels = self._make_stage(\n",
    "            self.stage2_cfg, num_channels)\n",
    "\n",
    "        self.stage3_cfg = cfg['MODEL']['EXTRA']['STAGE3']\n",
    "        num_channels = self.stage3_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage3_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition2 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage3, pre_stage_channels = self._make_stage(\n",
    "            self.stage3_cfg, num_channels)\n",
    "\n",
    "        self.stage4_cfg = cfg['MODEL']['EXTRA']['STAGE4']\n",
    "        num_channels = self.stage4_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage4_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition3 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage4, pre_stage_channels = self._make_stage(\n",
    "            self.stage4_cfg, num_channels, multi_scale_output=True)\n",
    "\n",
    "        # Classification Head\n",
    "        self.incre_modules, self.downsamp_modules, \\\n",
    "            self.final_layer = self._make_head(pre_stage_channels)\n",
    "\n",
    "        self.classifier = nn.Linear(2048, 1000)\n",
    "        \n",
    "        # addition\n",
    "        self.avgpool_1 = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.maxpool_1 = nn.AdaptiveMaxPool2d((1,1))\n",
    "        self.avgpool_2 = nn.AdaptiveAvgPool2d((2,2))\n",
    "        self.maxpool_2 = nn.AdaptiveMaxPool2d((2,2))\n",
    "        self.avgpool_3 = nn.AdaptiveAvgPool2d((3,3))\n",
    "        self.maxpool_3 = nn.AdaptiveMaxPool2d((3,3))\n",
    "        self.avgpool_4 = nn.AdaptiveAvgPool2d((4,4))\n",
    "        self.maxpool_4 = nn.AdaptiveMaxPool2d((4,4))\n",
    "        self.classifier = ClassBlock(6144, 751, 0.5)\n",
    "        self.cl = cl\n",
    "\n",
    "        self.vdsr = VDSR()\n",
    "        \n",
    "    def _make_head(self, pre_stage_channels):\n",
    "        head_block = Bottleneck\n",
    "        head_channels = [32, 64, 128, 256]\n",
    "\n",
    "        # Increasing the #channels on each resolution \n",
    "        # from C, 2C, 4C, 8C to 128, 256, 512, 1024\n",
    "        incre_modules = []\n",
    "        for i, channels  in enumerate(pre_stage_channels):\n",
    "            incre_module = self._make_layer(head_block,\n",
    "                                            channels,\n",
    "                                            head_channels[i],\n",
    "                                            1,\n",
    "                                            stride=1)\n",
    "            incre_modules.append(incre_module)\n",
    "        incre_modules = nn.ModuleList(incre_modules)\n",
    "            \n",
    "        # downsampling modules\n",
    "        downsamp_modules = []\n",
    "        for i in range(len(pre_stage_channels)-1):\n",
    "            in_channels = head_channels[i] * head_block.expansion\n",
    "            out_channels = head_channels[i+1] * head_block.expansion\n",
    "\n",
    "            downsamp_module = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels,\n",
    "                          out_channels=out_channels,\n",
    "                          kernel_size=3,\n",
    "                          stride=2,\n",
    "                          padding=1),\n",
    "                nn.BatchNorm2d(out_channels, momentum=BN_MOMENTUM),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "            downsamp_modules.append(downsamp_module)\n",
    "        downsamp_modules = nn.ModuleList(downsamp_modules)\n",
    "\n",
    "        final_layer = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=head_channels[3] * head_block.expansion,\n",
    "                out_channels=2048,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.BatchNorm2d(2048, momentum=BN_MOMENTUM),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        return incre_modules, downsamp_modules, final_layer\n",
    "\n",
    "    def _make_transition_layer(\n",
    "            self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "\n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_channels_pre_layer[i],\n",
    "                                  num_channels_cur_layer[i],\n",
    "                                  3,\n",
    "                                  1,\n",
    "                                  1,\n",
    "                                  bias=False),\n",
    "                        nn.BatchNorm2d(\n",
    "                            num_channels_cur_layer[i], momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=True)))\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                conv3x3s = []\n",
    "                for j in range(i+1-num_branches_pre):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] \\\n",
    "                        if j == i-num_branches_pre else inchannels\n",
    "                    conv3x3s.append(nn.Sequential(\n",
    "                        nn.Conv2d(\n",
    "                            inchannels, outchannels, 3, 2, 1, bias=False),\n",
    "                        nn.BatchNorm2d(outchannels, momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=True)))\n",
    "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
    "\n",
    "        return nn.ModuleList(transition_layers)\n",
    "\n",
    "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_stage(self, layer_config, num_inchannels,\n",
    "                    multi_scale_output=True):\n",
    "        num_modules = layer_config['NUM_MODULES']\n",
    "        num_branches = layer_config['NUM_BRANCHES']\n",
    "        num_blocks = layer_config['NUM_BLOCKS']\n",
    "        num_channels = layer_config['NUM_CHANNELS']\n",
    "        block = blocks_dict[layer_config['BLOCK']]\n",
    "        fuse_method = layer_config['FUSE_METHOD']\n",
    "\n",
    "        modules = []\n",
    "        for i in range(num_modules):\n",
    "            # multi_scale_output is only used last module\n",
    "            if not multi_scale_output and i == num_modules - 1:\n",
    "                reset_multi_scale_output = False\n",
    "            else:\n",
    "                reset_multi_scale_output = True\n",
    "\n",
    "            modules.append(\n",
    "                HighResolutionModule(num_branches,\n",
    "                                      block,\n",
    "                                      num_blocks,\n",
    "                                      num_inchannels,\n",
    "                                      num_channels,\n",
    "                                      fuse_method,\n",
    "                                      reset_multi_scale_output)\n",
    "            )\n",
    "            num_inchannels = modules[-1].get_num_inchannels()\n",
    "\n",
    "        return nn.Sequential(*modules), num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vdsr(x)\n",
    "        sr = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n",
    "            if self.transition1[i] is not None:\n",
    "                x_list.append(self.transition1[i](x))\n",
    "            else:\n",
    "                x_list.append(x)\n",
    "        y_list_s2 = self.stage2(x_list)\n",
    "       \n",
    "        \n",
    "        x_list = []\n",
    "        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n",
    "            if self.transition2[i] is not None:\n",
    "                x_list.append(self.transition2[i](y_list_s2[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list_s2[i])\n",
    "        y_list_s3 = self.stage3(x_list)\n",
    "        \n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
    "            if self.transition3[i] is not None:\n",
    "                x_list.append(self.transition3[i](y_list_s3[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list_s3[i])\n",
    "                \n",
    "        y_list = self.stage4(x_list)\n",
    "        \n",
    "        \n",
    "        for i in range(4):\n",
    "            y_list[i] = self.incre_modules[i](y_list[i])\n",
    "               \n",
    "        y_list[0] = self.avgpool_4(y_list[0])+0.5*self.maxpool_4(y_list[0])\n",
    "        y_list[1] = self.avgpool_2(y_list[1])+0.2*self.maxpool_2(y_list[1])\n",
    "        y_list[2] = self.avgpool_2(y_list[2])+0.2*self.maxpool_2(y_list[2])\n",
    "        y_list[3] = self.avgpool_1(y_list[3])+0.2*self.maxpool_1(y_list[3])\n",
    "        \n",
    "        y_list[0] = y_list[0].view((y_list[0].shape)[0],-1)\n",
    "        y_list[1] = y_list[1].view((y_list[1].shape)[0],-1)\n",
    "        y_list[2] = y_list[2].view((y_list[2].shape)[0],-1)\n",
    "        y_list[3] = y_list[3].view((y_list[3].shape)[0],-1)\n",
    "        \n",
    "        y_tlp = torch.cat((y_list[0],y_list[1],y_list[2],y_list[3]),1)\n",
    "        y_cls = self.classifier(y_tlp)\n",
    "        \n",
    "        if self.cl:\n",
    "            return y_tlp,y_list[0],y_list[1],y_list[2],y_list[3],y_cls,sr\n",
    "        self.classifier.classifier = nn.Sequential()\n",
    "        y_cls_ft = self.classifier(y_tlp)\n",
    "        return torch.cat((y_tlp,y_cls_ft),1)\n",
    "    \n",
    "    \n",
    "    def init_weights(self, pretrained='',):\n",
    "        logger.info('=> init weights from normal distribution')\n",
    "        for m in self.modules():\n",
    "            if m.__class__.__name__=='VDSR':\n",
    "                break\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        if os.path.isfile(pretrained):\n",
    "            pretrained_dict = torch.load(pretrained)\n",
    "            logger.info('=> loading pretrained model {}'.format(pretrained))\n",
    "            model_dict = self.state_dict()\n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
    "                               if k in model_dict.keys()}\n",
    "            for k, _ in pretrained_dict.items():\n",
    "                logger.info(\n",
    "                    '=> loading {} pretrained model {}'.format(k, pretrained))\n",
    "            model_dict.update(pretrained_dict)\n",
    "            self.load_state_dict(model_dict)\n",
    "            \n",
    "def get_cls_net(cl ,config, **kwargs):\n",
    "    model = HighResolutionNet(cl, config, **kwargs)\n",
    "    model.init_weights('hrnetv2_w32_imagenet_pretrained.pth')\n",
    "    return model\n",
    "\n",
    "from config import config\n",
    "config.defrost()\n",
    "config.merge_from_file(r'cls_hrnet_w32_sgd_lr5e-2_wd1e-4_bs32_x100.yaml')\n",
    "config.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-Siamese HRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tHighResolutionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, cl, cfg, **kwargs):\n",
    "        super(tHighResolutionNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.stage1_cfg = cfg['MODEL']['EXTRA']['STAGE1']\n",
    "        num_channels = self.stage1_cfg['NUM_CHANNELS'][0]\n",
    "        block = blocks_dict[self.stage1_cfg['BLOCK']]\n",
    "        num_blocks = self.stage1_cfg['NUM_BLOCKS'][0]\n",
    "        self.layer1 = self._make_layer(block, 64, num_channels, num_blocks)\n",
    "        stage1_out_channel = block.expansion*num_channels\n",
    "\n",
    "        self.stage2_cfg = cfg['MODEL']['EXTRA']['STAGE2']\n",
    "        num_channels = self.stage2_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage2_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition1 = self._make_transition_layer(\n",
    "            [stage1_out_channel], num_channels)\n",
    "        self.stage2, pre_stage_channels = self._make_stage(\n",
    "            self.stage2_cfg, num_channels)\n",
    "\n",
    "        self.stage3_cfg = cfg['MODEL']['EXTRA']['STAGE3']\n",
    "        num_channels = self.stage3_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage3_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition2 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage3, pre_stage_channels = self._make_stage(\n",
    "            self.stage3_cfg, num_channels)\n",
    "\n",
    "        self.stage4_cfg = cfg['MODEL']['EXTRA']['STAGE4']\n",
    "        num_channels = self.stage4_cfg['NUM_CHANNELS']\n",
    "        block = blocks_dict[self.stage4_cfg['BLOCK']]\n",
    "        num_channels = [\n",
    "            num_channels[i] * block.expansion for i in range(len(num_channels))]\n",
    "        self.transition3 = self._make_transition_layer(\n",
    "            pre_stage_channels, num_channels)\n",
    "        self.stage4, pre_stage_channels = self._make_stage(\n",
    "            self.stage4_cfg, num_channels, multi_scale_output=True)\n",
    "\n",
    "        # Classification Head\n",
    "        self.incre_modules, self.downsamp_modules, \\\n",
    "            self.final_layer = self._make_head(pre_stage_channels)\n",
    "\n",
    "        self.classifier = nn.Linear(2048, 1000)\n",
    "        \n",
    "        # addition\n",
    "        self.avgpool_1 = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.maxpool_1 = nn.AdaptiveMaxPool2d((1,1))\n",
    "        self.avgpool_2 = nn.AdaptiveAvgPool2d((2,2))\n",
    "        self.maxpool_2 = nn.AdaptiveMaxPool2d((2,2))\n",
    "        self.avgpool_3 = nn.AdaptiveAvgPool2d((3,3))\n",
    "        self.maxpool_3 = nn.AdaptiveMaxPool2d((3,3))\n",
    "        self.avgpool_4 = nn.AdaptiveAvgPool2d((4,4))\n",
    "        self.maxpool_4 = nn.AdaptiveMaxPool2d((4,4))\n",
    "        self.classifier = ClassBlock(6144, 751, 0.5)\n",
    "        self.cl = cl\n",
    "        \n",
    "    def _make_head(self, pre_stage_channels):\n",
    "        head_block = Bottleneck\n",
    "        head_channels = [32, 64, 128, 256]\n",
    "\n",
    "        # Increasing the #channels on each resolution \n",
    "        # from C, 2C, 4C, 8C to 128, 256, 512, 1024\n",
    "        incre_modules = []\n",
    "        for i, channels  in enumerate(pre_stage_channels):\n",
    "            incre_module = self._make_layer(head_block,\n",
    "                                            channels,\n",
    "                                            head_channels[i],\n",
    "                                            1,\n",
    "                                            stride=1)\n",
    "            incre_modules.append(incre_module)\n",
    "        incre_modules = nn.ModuleList(incre_modules)\n",
    "            \n",
    "        # downsampling modules\n",
    "        downsamp_modules = []\n",
    "        for i in range(len(pre_stage_channels)-1):\n",
    "            in_channels = head_channels[i] * head_block.expansion\n",
    "            out_channels = head_channels[i+1] * head_block.expansion\n",
    "\n",
    "            downsamp_module = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels,\n",
    "                          out_channels=out_channels,\n",
    "                          kernel_size=3,\n",
    "                          stride=2,\n",
    "                          padding=1),\n",
    "                nn.BatchNorm2d(out_channels, momentum=BN_MOMENTUM),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "            downsamp_modules.append(downsamp_module)\n",
    "        downsamp_modules = nn.ModuleList(downsamp_modules)\n",
    "\n",
    "        final_layer = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=head_channels[3] * head_block.expansion,\n",
    "                out_channels=2048,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.BatchNorm2d(2048, momentum=BN_MOMENTUM),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        return incre_modules, downsamp_modules, final_layer\n",
    "\n",
    "    def _make_transition_layer(\n",
    "            self, num_channels_pre_layer, num_channels_cur_layer):\n",
    "        num_branches_cur = len(num_channels_cur_layer)\n",
    "        num_branches_pre = len(num_channels_pre_layer)\n",
    "\n",
    "        transition_layers = []\n",
    "        for i in range(num_branches_cur):\n",
    "            if i < num_branches_pre:\n",
    "                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n",
    "                    transition_layers.append(nn.Sequential(\n",
    "                        nn.Conv2d(num_channels_pre_layer[i],\n",
    "                                  num_channels_cur_layer[i],\n",
    "                                  3,\n",
    "                                  1,\n",
    "                                  1,\n",
    "                                  bias=False),\n",
    "                        nn.BatchNorm2d(\n",
    "                            num_channels_cur_layer[i], momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=True)))\n",
    "                else:\n",
    "                    transition_layers.append(None)\n",
    "            else:\n",
    "                conv3x3s = []\n",
    "                for j in range(i+1-num_branches_pre):\n",
    "                    inchannels = num_channels_pre_layer[-1]\n",
    "                    outchannels = num_channels_cur_layer[i] \\\n",
    "                        if j == i-num_branches_pre else inchannels\n",
    "                    conv3x3s.append(nn.Sequential(\n",
    "                        nn.Conv2d(\n",
    "                            inchannels, outchannels, 3, 2, 1, bias=False),\n",
    "                        nn.BatchNorm2d(outchannels, momentum=BN_MOMENTUM),\n",
    "                        nn.ReLU(inplace=True)))\n",
    "                transition_layers.append(nn.Sequential(*conv3x3s))\n",
    "\n",
    "        return nn.ModuleList(transition_layers)\n",
    "\n",
    "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample))\n",
    "        inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_stage(self, layer_config, num_inchannels,\n",
    "                    multi_scale_output=True):\n",
    "        num_modules = layer_config['NUM_MODULES']\n",
    "        num_branches = layer_config['NUM_BRANCHES']\n",
    "        num_blocks = layer_config['NUM_BLOCKS']\n",
    "        num_channels = layer_config['NUM_CHANNELS']\n",
    "        block = blocks_dict[layer_config['BLOCK']]\n",
    "        fuse_method = layer_config['FUSE_METHOD']\n",
    "\n",
    "        modules = []\n",
    "        for i in range(num_modules):\n",
    "            # multi_scale_output is only used last module\n",
    "            if not multi_scale_output and i == num_modules - 1:\n",
    "                reset_multi_scale_output = False\n",
    "            else:\n",
    "                reset_multi_scale_output = True\n",
    "\n",
    "            modules.append(\n",
    "                HighResolutionModule(num_branches,\n",
    "                                      block,\n",
    "                                      num_blocks,\n",
    "                                      num_inchannels,\n",
    "                                      num_channels,\n",
    "                                      fuse_method,\n",
    "                                      reset_multi_scale_output)\n",
    "            )\n",
    "            num_inchannels = modules[-1].get_num_inchannels()\n",
    "\n",
    "        return nn.Sequential(*modules), num_inchannels\n",
    "\n",
    "    def forward(self, x):\n",
    "        sr = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n",
    "            if self.transition1[i] is not None:\n",
    "                x_list.append(self.transition1[i](x))\n",
    "            else:\n",
    "                x_list.append(x)\n",
    "        y_list_s2 = self.stage2(x_list)\n",
    "       \n",
    "        \n",
    "        x_list = []\n",
    "        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n",
    "            if self.transition2[i] is not None:\n",
    "                x_list.append(self.transition2[i](y_list_s2[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list_s2[i])\n",
    "        y_list_s3 = self.stage3(x_list)\n",
    "        \n",
    "\n",
    "        x_list = []\n",
    "        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n",
    "            if self.transition3[i] is not None:\n",
    "                x_list.append(self.transition3[i](y_list_s3[-1]))\n",
    "            else:\n",
    "                x_list.append(y_list_s3[i])\n",
    "                \n",
    "        y_list = self.stage4(x_list)\n",
    "        \n",
    "        \n",
    "        for i in range(4):\n",
    "            y_list[i] = self.incre_modules[i](y_list[i])\n",
    "            \n",
    "       \n",
    "        y_list[0] = self.avgpool_4(y_list[0])+0.5*self.maxpool_4(y_list[0])\n",
    "        y_list[1] = self.avgpool_2(y_list[1])+0.2*self.maxpool_2(y_list[1])\n",
    "        y_list[2] = self.avgpool_2(y_list[2])+0.2*self.maxpool_2(y_list[2])\n",
    "        y_list[3] = self.avgpool_1(y_list[3])+0.2*self.maxpool_1(y_list[3])\n",
    "        \n",
    "        y_list[0] = y_list[0].view((y_list[0].shape)[0],-1)\n",
    "        y_list[1] = y_list[1].view((y_list[1].shape)[0],-1)\n",
    "        y_list[2] = y_list[2].view((y_list[2].shape)[0],-1)\n",
    "        y_list[3] = y_list[3].view((y_list[3].shape)[0],-1)\n",
    "        \n",
    "        y_tlp = torch.cat((y_list[0],y_list[1],y_list[2],y_list[3]),1)\n",
    "        y_cls = self.classifier(y_tlp)\n",
    "        \n",
    "        if self.cl:\n",
    "            return y_tlp,y_list[0],y_list[1],y_list[2],y_list[3],y_cls,sr\n",
    "        self.classifier.classifier = nn.Sequential()\n",
    "        y_cls_ft = self.classifier(y_tlp)\n",
    "        return torch.cat((y_tlp,y_cls_ft),1)\n",
    "    \n",
    "    \n",
    "    def init_weights(self, pretrained='',):\n",
    "        logger.info('=> init weights from normal distribution')\n",
    "        for m in self.modules():\n",
    "            if m.__class__.__name__=='VDSR':\n",
    "                break\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        if os.path.isfile(pretrained):\n",
    "            pretrained_dict = torch.load(pretrained)\n",
    "            logger.info('=> loading pretrained model {}'.format(pretrained))\n",
    "            model_dict = self.state_dict()\n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
    "                               if k in model_dict.keys()}\n",
    "            for k, _ in pretrained_dict.items():\n",
    "                logger.info(\n",
    "                    '=> loading {} pretrained model {}'.format(k, pretrained))\n",
    "            model_dict.update(pretrained_dict)\n",
    "            self.load_state_dict(model_dict)\n",
    "            \n",
    "def get_cls_tnet(cl ,config, **kwargs):\n",
    "    model = tHighResolutionNet(cl, config, **kwargs)\n",
    "    model.init_weights('hrnetv2_w32_imagenet_pretrained.pth')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Market1501 loaded\n",
      "Dataset statistics:\n",
      "  ------------------------------\n",
      "  subset   | # ids | # images\n",
      "  ------------------------------\n",
      "  train    |   751 |    12936\n",
      "  query    |   750 |     3368\n",
      "  gallery  |   751 |    13149\n",
      "  ------------------------------\n",
      "  total    |  1501 |    29453\n",
      "  ------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch1_5\\lib\\site-packages\\ipykernel_launcher.py:61: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "D:\\Anaconda3\\envs\\pytorch1_5\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "D:\\Anaconda3\\envs\\pytorch1_5\\lib\\site-packages\\ipykernel_launcher.py:64: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "D:\\Anaconda3\\envs\\pytorch1_5\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "HighResolutionNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (transition1): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage2): Sequential(\n",
      "    (0): HighResolutionModule(\n",
      "      (branches): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): None\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): None\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (transition2): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (0): HighResolutionModule(\n",
      "      (branches): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): None\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): None\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): None\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): HighResolutionModule(\n",
      "      (branches): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): None\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): None\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): None\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): HighResolutionModule(\n",
      "      (branches): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): None\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): None\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): None\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (3): HighResolutionModule(\n",
      "      (branches): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): None\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): None\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): None\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (transition3): ModuleList(\n",
      "    (0): None\n",
      "    (1): None\n",
      "    (2): None\n",
      "    (3): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (0): HighResolutionModule(\n",
      "      (branches): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): None\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=8.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): None\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): None\n",
      "          (3): Sequential(\n",
      "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (3): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(32, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): None\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): HighResolutionModule(\n",
      "      (branches): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): None\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=8.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): None\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): None\n",
      "          (3): Sequential(\n",
      "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (3): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(32, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): None\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): HighResolutionModule(\n",
      "      (branches): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): None\n",
      "          (1): Sequential(\n",
      "            (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=8.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): None\n",
      "          (2): Sequential(\n",
      "            (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "          (3): Sequential(\n",
      "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=4.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (2): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): None\n",
      "          (3): Sequential(\n",
      "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "          )\n",
      "        )\n",
      "        (3): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(32, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (3): None\n",
      "        )\n",
      "      )\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (incre_modules): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (downsamp_modules): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (final_layer): Sequential(\n",
      "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): ClassBlock(\n",
      "    (add_block): Sequential(\n",
      "      (0): Linear(in_features=6144, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=751, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool_1): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (maxpool_1): AdaptiveMaxPool2d(output_size=(1, 1))\n",
      "  (avgpool_2): AdaptiveAvgPool2d(output_size=(2, 2))\n",
      "  (maxpool_2): AdaptiveMaxPool2d(output_size=(2, 2))\n",
      "  (avgpool_3): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "  (maxpool_3): AdaptiveMaxPool2d(output_size=(3, 3))\n",
      "  (avgpool_4): AdaptiveAvgPool2d(output_size=(4, 4))\n",
      "  (maxpool_4): AdaptiveMaxPool2d(output_size=(4, 4))\n",
      "  (vdsr): VDSR(\n",
      "    (residual_layer): Sequential(\n",
      "      (0): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (8): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (9): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (10): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (11): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (12): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (13): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (14): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (15): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (16): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (17): Conv_ReLU_Block(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (ca): ChannelAttention(\n",
      "          (module): Sequential(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (4): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (input): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (output): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0/70\n",
      "----------\n",
      "0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch1_5\\lib\\site-packages\\apex\\amp\\wrap.py:111: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  return orig_fn(arg0, *new_args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 8.0967 cls_acc: 0.0205\n",
      "Training complete in 8m 59s\n",
      "\n",
      "Epoch 1/70\n",
      "----------\n",
      "0.0003\n",
      "train Loss: 7.7694 cls_acc: 0.0517\n",
      "Training complete in 17m 56s\n",
      "\n",
      "Epoch 2/70\n",
      "----------\n",
      "0.0003\n",
      "train Loss: 7.3812 cls_acc: 0.0530\n",
      "Training complete in 26m 53s\n",
      "\n",
      "Epoch 3/70\n",
      "----------\n",
      "0.0003\n",
      "train Loss: 7.0054 cls_acc: 0.0678\n",
      "Training complete in 35m 49s\n",
      "\n",
      "Epoch 4/70\n",
      "----------\n",
      "0.0003\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 6.6868 cls_acc: 0.0952\n",
      "Training complete in 44m 45s\n",
      "\n",
      "Epoch 5/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 6.2859 cls_acc: 0.1286\n",
      "Training complete in 53m 43s\n",
      "\n",
      "Epoch 6/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 5.2666 cls_acc: 0.2575\n",
      "Training complete in 62m 40s\n",
      "\n",
      "Epoch 7/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 4.5598 cls_acc: 0.3749\n",
      "Training complete in 71m 35s\n",
      "\n",
      "Epoch 8/70\n",
      "----------\n",
      "0.0085\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 4.0406 cls_acc: 0.4753\n",
      "Training complete in 80m 30s\n",
      "\n",
      "Epoch 9/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 3.6470 cls_acc: 0.5599\n",
      "Training complete in 89m 25s\n",
      "\n",
      "Epoch 10/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 3.3601 cls_acc: 0.6212\n",
      "Training complete in 98m 22s\n",
      "\n",
      "Epoch 11/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 3.1543 cls_acc: 0.6810\n",
      "Training complete in 107m 18s\n",
      "\n",
      "Epoch 12/70\n",
      "----------\n",
      "0.0085\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n",
      "train Loss: 2.9839 cls_acc: 0.7152\n",
      "Training complete in 116m 12s\n",
      "\n",
      "Epoch 13/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.8573 cls_acc: 0.7505\n",
      "Training complete in 125m 7s\n",
      "\n",
      "Epoch 14/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.7356 cls_acc: 0.7744\n",
      "Training complete in 134m 1s\n",
      "\n",
      "Epoch 15/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.6462 cls_acc: 0.7997\n",
      "Training complete in 142m 58s\n",
      "\n",
      "Epoch 16/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.5689 cls_acc: 0.8149\n",
      "Training complete in 151m 54s\n",
      "\n",
      "Epoch 17/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.4815 cls_acc: 0.8344\n",
      "Training complete in 160m 51s\n",
      "\n",
      "Epoch 18/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.4134 cls_acc: 0.8534\n",
      "Training complete in 169m 46s\n",
      "\n",
      "Epoch 19/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.3612 cls_acc: 0.8592\n",
      "Training complete in 178m 41s\n",
      "\n",
      "Epoch 20/70\n",
      "----------\n",
      "0.0085\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 2.3259 cls_acc: 0.8650\n",
      "Training complete in 187m 35s\n",
      "\n",
      "Epoch 21/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.2717 cls_acc: 0.8738\n",
      "Training complete in 196m 30s\n",
      "\n",
      "Epoch 22/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.2487 cls_acc: 0.8755\n",
      "Training complete in 205m 24s\n",
      "\n",
      "Epoch 23/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.2211 cls_acc: 0.8799\n",
      "Training complete in 214m 18s\n",
      "\n",
      "Epoch 24/70\n",
      "----------\n",
      "0.0085\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 2.1841 cls_acc: 0.8853\n",
      "Training complete in 223m 14s\n",
      "\n",
      "Epoch 25/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.1397 cls_acc: 0.8901\n",
      "Training complete in 232m 9s\n",
      "\n",
      "Epoch 26/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.1153 cls_acc: 0.8915\n",
      "Training complete in 241m 4s\n",
      "\n",
      "Epoch 27/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.0950 cls_acc: 0.8965\n",
      "Training complete in 249m 59s\n",
      "\n",
      "Epoch 28/70\n",
      "----------\n",
      "0.0085\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 2.0907 cls_acc: 0.8973\n",
      "Training complete in 258m 55s\n",
      "\n",
      "Epoch 29/70\n",
      "----------\n",
      "0.0085\n",
      "train Loss: 2.0886 cls_acc: 0.8980\n",
      "Training complete in 267m 51s\n",
      "\n",
      "Epoch 30/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.9879 cls_acc: 0.9056\n",
      "Training complete in 276m 47s\n",
      "\n",
      "Epoch 31/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.9458 cls_acc: 0.9126\n",
      "Training complete in 285m 43s\n",
      "\n",
      "Epoch 32/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.9191 cls_acc: 0.9123\n",
      "Training complete in 294m 37s\n",
      "\n",
      "Epoch 33/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 1.9093 cls_acc: 0.9133\n",
      "Training complete in 303m 33s\n",
      "\n",
      "Epoch 34/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.9046 cls_acc: 0.9143\n",
      "Training complete in 312m 28s\n",
      "\n",
      "Epoch 35/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8975 cls_acc: 0.9152\n",
      "Training complete in 321m 25s\n",
      "\n",
      "Epoch 36/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8806 cls_acc: 0.9115\n",
      "Training complete in 330m 18s\n",
      "\n",
      "Epoch 37/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 1.8794 cls_acc: 0.9137\n",
      "Training complete in 339m 12s\n",
      "\n",
      "Epoch 38/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8773 cls_acc: 0.9142\n",
      "Training complete in 348m 7s\n",
      "\n",
      "Epoch 39/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8719 cls_acc: 0.9135\n",
      "Training complete in 357m 1s\n",
      "\n",
      "Epoch 40/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8717 cls_acc: 0.9153\n",
      "Training complete in 365m 58s\n",
      "\n",
      "Epoch 41/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8588 cls_acc: 0.9120\n",
      "Training complete in 374m 52s\n",
      "\n",
      "Epoch 42/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 1.8600 cls_acc: 0.9138\n",
      "Training complete in 383m 46s\n",
      "\n",
      "Epoch 43/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8529 cls_acc: 0.9119\n",
      "Training complete in 392m 39s\n",
      "\n",
      "Epoch 44/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8527 cls_acc: 0.9141\n",
      "Training complete in 401m 33s\n",
      "\n",
      "Epoch 45/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8523 cls_acc: 0.9142\n",
      "Training complete in 410m 28s\n",
      "\n",
      "Epoch 46/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 1.8458 cls_acc: 0.9143\n",
      "Training complete in 419m 22s\n",
      "\n",
      "Epoch 47/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8447 cls_acc: 0.9141\n",
      "Training complete in 428m 17s\n",
      "\n",
      "Epoch 48/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8429 cls_acc: 0.9163\n",
      "Training complete in 437m 12s\n",
      "\n",
      "Epoch 49/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8366 cls_acc: 0.9122\n",
      "Training complete in 446m 5s\n",
      "\n",
      "Epoch 50/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8294 cls_acc: 0.9106\n",
      "Training complete in 454m 58s\n",
      "\n",
      "Epoch 51/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8307 cls_acc: 0.9124\n",
      "Training complete in 463m 52s\n",
      "\n",
      "Epoch 52/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 1.8323 cls_acc: 0.9143\n",
      "Training complete in 472m 46s\n",
      "\n",
      "Epoch 53/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8314 cls_acc: 0.9143\n",
      "Training complete in 481m 41s\n",
      "\n",
      "Epoch 54/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8256 cls_acc: 0.9143\n",
      "Training complete in 490m 36s\n",
      "\n",
      "Epoch 55/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8267 cls_acc: 0.9163\n",
      "Training complete in 499m 32s\n",
      "\n",
      "Epoch 56/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8258 cls_acc: 0.9163\n",
      "Training complete in 508m 28s\n",
      "\n",
      "Epoch 57/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8224 cls_acc: 0.9164\n",
      "Training complete in 517m 23s\n",
      "\n",
      "Epoch 58/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8220 cls_acc: 0.9164\n",
      "Training complete in 526m 18s\n",
      "\n",
      "Epoch 59/70\n",
      "----------\n",
      "0.0008500000000000001\n",
      "train Loss: 1.8174 cls_acc: 0.9144\n",
      "Training complete in 535m 13s\n",
      "\n",
      "Epoch 60/70\n",
      "----------\n",
      "8.500000000000002e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n",
      "train Loss: 1.8068 cls_acc: 0.9108\n",
      "Training complete in 544m 6s\n",
      "\n",
      "Epoch 61/70\n",
      "----------\n",
      "8.500000000000002e-05\n",
      "train Loss: 1.8100 cls_acc: 0.9126\n",
      "Training complete in 552m 59s\n",
      "\n",
      "Epoch 62/70\n",
      "----------\n",
      "8.500000000000002e-05\n",
      "train Loss: 1.8104 cls_acc: 0.9147\n",
      "Training complete in 561m 53s\n",
      "\n",
      "Epoch 63/70\n",
      "----------\n",
      "8.500000000000002e-05\n",
      "train Loss: 1.8146 cls_acc: 0.9165\n",
      "Training complete in 570m 49s\n",
      "\n",
      "Epoch 64/70\n",
      "----------\n",
      "8.500000000000002e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 1.8115 cls_acc: 0.9144\n",
      "Training complete in 579m 42s\n",
      "\n",
      "Epoch 65/70\n",
      "----------\n",
      "8.500000000000002e-05\n",
      "train Loss: 1.8118 cls_acc: 0.9145\n",
      "Training complete in 588m 38s\n",
      "\n",
      "Epoch 66/70\n",
      "----------\n",
      "8.500000000000002e-05\n",
      "train Loss: 1.8122 cls_acc: 0.9164\n",
      "Training complete in 597m 33s\n",
      "\n",
      "Epoch 67/70\n",
      "----------\n",
      "8.500000000000002e-05\n",
      "train Loss: 1.8078 cls_acc: 0.9146\n",
      "Training complete in 606m 25s\n",
      "\n",
      "Epoch 68/70\n",
      "----------\n",
      "8.500000000000002e-05\n",
      "train Loss: 1.8100 cls_acc: 0.9146\n",
      "Training complete in 615m 2s\n",
      "\n",
      "Epoch 69/70\n",
      "----------\n",
      "8.500000000000002e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.8141 cls_acc: 0.9164\n",
      "Training complete in 623m 40s\n",
      "\n",
      "Epoch 70/70\n",
      "----------\n",
      "8.500000000000002e-05\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n",
      "train Loss: 1.8073 cls_acc: 0.9146\n",
      "Training complete in 632m 17s\n",
      "\n",
      "Training complete in 632m 17s\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# configuration\n",
    "# -----\n",
    "\n",
    "fp16 = True\n",
    "gpu_ids = '0'\n",
    "name = 'ft_net_v7'\n",
    "batchsize = 24\n",
    "color_jitter = False\n",
    "str_ids = gpu_ids.split(',')\n",
    "gpu_ids = []\n",
    "\n",
    "if not os.path.exists('./model/%s' % name):\n",
    "        os.makedirs('./model/%s' % name)\n",
    "for str_id in str_ids:\n",
    "    gid = int(str_id)\n",
    "    if gid >=0:\n",
    "        gpu_ids.append(gid)\n",
    "\n",
    "# set gpu ids\n",
    "if len(gpu_ids)>0:\n",
    "    torch.cuda.set_device(gpu_ids[0])\n",
    "######################################################################\n",
    "# dataloader\n",
    "# ------\n",
    "\n",
    "dataset = mydataset.Market1501(root=r'C:\\Users\\reID\\Desktop\\HRNet ReID', split_id=0)\n",
    "\n",
    "dataloaders = DataLoader(\n",
    "        ImageDatasettrain(dataset.train, 256, 128),\n",
    "        sampler= RandomIdentitySampler(ImageDatasettrain(dataset.train, 256, 128),batchsize,4),\n",
    "        batch_size=batchsize, shuffle=False, num_workers=0,\n",
    "        pin_memory=False, drop_last=True,\n",
    ")\n",
    "\n",
    "dataset_sizes = 12936\n",
    "num_class = 751\n",
    "use_gpu = torch.cuda.is_available()\n",
    "######################################################################\n",
    "# Training\n",
    "# ------\n",
    "\n",
    "y_loss = {}\n",
    "y_loss['train'] = []\n",
    "y_loss['val'] = []\n",
    "y_err = {}\n",
    "y_err['train'] = []\n",
    "y_err['val'] = []\n",
    "\n",
    "def train_model(model, teacher, optimizers, criterion, triplet, cri_sr, num_epochs):\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        step = (epoch//30)\n",
    "        lr = 0.0085*pow(0.1,step)   \n",
    "        optimizer = optimizers\n",
    "        \n",
    "        if epoch < 5:\n",
    "            lr = 3e-4\n",
    "        \n",
    "        for param_group in optimizer.param_groups:\n",
    "        \tparam_group['lr'] = lr\n",
    "        print(param_group['lr'])\n",
    "            \n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "                teacher.train(False)\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders:\n",
    "                # get the inputs\n",
    "                inputs_res, inputs, labels ,_ ,_ = data\n",
    "                now_batch_size,c,h,w = inputs.shape\n",
    "                if now_batch_size<batchsize:\n",
    "                    continue\n",
    "                if use_gpu:\n",
    "                    inputs_res = inputs_res.cuda()\n",
    "                    inputs = inputs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                else:\n",
    "                    inputs_res, inputs, labels = Variable(inputs_res), Variable(inputs), Variable(labels)\n",
    "                temp_loss = []\n",
    "\n",
    "                optimizer.zero_grad()                \n",
    "                outputs= model(inputs_res)\n",
    "                src_outputs=teacher(inputs)\n",
    "                _, preds = torch.max(outputs[5].data, 1)\n",
    "                \n",
    "                loss1 = criterion(outputs[5], labels)\n",
    "                loss2 = triplet(outputs[0], labels)[0]\n",
    "                loss3 = triplet(outputs[1], labels)[0]\n",
    "                loss4 = triplet(outputs[2], labels)[0]\n",
    "                loss5 = triplet(outputs[3], labels)[0]\n",
    "                loss6 = triplet(outputs[4], labels)[0]\n",
    "                \n",
    "                loss7 = cri_sr(src_outputs[0],outputs[0])+cri_sr(src_outputs[1],outputs[1])+cri_sr(src_outputs[2],outputs[2])+cri_sr(src_outputs[3],outputs[3])+cri_sr(src_outputs[4],outputs[4])+cri_sr(src_outputs[5],outputs[5])\n",
    "                \n",
    "                loss8 = cri_sr(inputs,outputs[6])\n",
    "                \n",
    "                loss = 1.15*loss1 + (loss2+loss3+loss4+loss5+loss6)/5 + 0.5*loss8 + 0.5*loss7\n",
    "\n",
    "                if phase == 'train':\n",
    "                    if fp16:\n",
    "                        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                            scaled_loss.backward()\n",
    "                    else:\n",
    "                        loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                if int(version[2]) > 3: # for the new version like 0.4.0 and 0.5.0\n",
    "                    running_loss += loss.item() * now_batch_size\n",
    "                else :  # for the old version like 0.3.0 and 0.3.1\n",
    "                    running_loss += loss.data[0] * now_batch_size\n",
    "                a = float(torch.sum(preds == labels.data))\n",
    "                #b = float(torch.sum(preds2 == labels.data))\n",
    "               \n",
    "                running_corrects_1 = a \n",
    "                running_corrects_2 = running_corrects_1\n",
    "                running_corrects +=running_corrects_2\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes\n",
    "            epoch_acc = running_corrects / dataset_sizes\n",
    "            \n",
    "            # 在日志文件中记录每个epoch的精度和loss\n",
    "            with open('./model/%s/%s.txt' %(name,name),'a') as acc_file:\n",
    "                acc_file.write('Epoch: %2d, csl_Precision: %.8f, Loss: %.8f\\n' % (epoch, epoch_acc, epoch_loss))\n",
    "            print('{} Loss: {:.4f} cls_acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            y_loss[phase].append(epoch_loss)\n",
    "            y_err[phase].append(1.0-epoch_acc)            \n",
    "\n",
    "            if phase == 'train':\n",
    "                last_model_wts = model.state_dict()\n",
    "                if epoch < 150:\n",
    "                    # 每10个epoch保存一次网络\n",
    "                     if epoch%5 == 0:\n",
    "                         save_network(model, epoch)\n",
    "                     draw_curve(epoch)\n",
    "                else:\n",
    "                    save_network(model, epoch)\n",
    "                    draw_curve(epoch)\n",
    "                    \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(last_model_wts)\n",
    "    save_network(model, 'last')\n",
    "    return model\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# plot\n",
    "# ------\n",
    "x_epoch = []\n",
    "fig = plt.figure(figsize=(32,16))\n",
    "ax0 = fig.add_subplot(121, title=\"loss\")\n",
    "ax1 = fig.add_subplot(122, title=\"top1err\")\n",
    "def draw_curve(current_epoch):\n",
    "    x_epoch.append(current_epoch)\n",
    "    ax0.plot(x_epoch, y_loss['train'], 'bo-', label='train')\n",
    "    ax1.plot(x_epoch, y_err['train'], 'bo-', label='train')\n",
    "    if current_epoch == 0:\n",
    "        ax0.legend()\n",
    "        ax1.legend()\n",
    "    fig.savefig( os.path.join('./model',name,'train.jpg'))\n",
    "\n",
    "######################################################################\n",
    "# save\n",
    "#---------------------------\n",
    "def save_network(network, epoch_label):\n",
    "    save_filename = 'net_%s.pth'% epoch_label\n",
    "    save_path = os.path.join('./model',name,save_filename)\n",
    "    torch.save(network.cpu().state_dict(), save_path)\n",
    "    if torch.cuda.is_available():\n",
    "        network.cuda(gpu_ids[0])\n",
    "\n",
    "hrnet_train = get_cls_net(True, config)\n",
    "model = hrnet_train\n",
    "teacher = get_cls_tnet(True, config)\n",
    "teacher.load_state_dict(torch.load(r'model\\ft_net_v4\\net_70.pth'))\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    teacher = teacher.cuda()\n",
    "\n",
    "sr_params = list(map(id, model.vdsr.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in sr_params,model.parameters())\n",
    "\n",
    "optimizers = torch.optim.SGD([\n",
    "            {'params': base_params, 'lr' : 0.0085},\n",
    "            {'params': model.vdsr.parameters(), 'lr': 0.001}],\n",
    "             weight_decay=5e-4,momentum=0.9, nesterov=True)\n",
    "\n",
    "if fp16:\n",
    "    model, optimizers = amp.initialize(model, optimizers, opt_level = \"O1\")\n",
    "    \n",
    "print(model)\n",
    "\n",
    "triplet = TripletLoss(margin=0.3)\n",
    "criterion = CrossEntropyLabelSmooth(num_class)\n",
    "cri_sr=nn.L1Loss()\n",
    "\n",
    "model = train_model(model,teacher,optimizers, criterion, triplet, cri_sr, num_epochs=71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------test-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch1_5\\lib\\site-packages\\ipykernel_launcher.py:61: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "D:\\Anaconda3\\envs\\pytorch1_5\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "D:\\Anaconda3\\envs\\pytorch1_5\\lib\\site-packages\\ipykernel_launcher.py:64: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "D:\\Anaconda3\\envs\\pytorch1_5\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "16\n",
      "24\n",
      "32\n",
      "40\n",
      "48\n",
      "56\n",
      "64\n",
      "72\n",
      "80\n",
      "88\n",
      "96\n",
      "104\n",
      "112\n",
      "120\n",
      "128\n",
      "136\n",
      "144\n",
      "152\n",
      "160\n",
      "168\n",
      "176\n",
      "184\n",
      "192\n",
      "200\n",
      "208\n",
      "216\n",
      "224\n",
      "232\n",
      "240\n",
      "248\n",
      "256\n",
      "264\n",
      "272\n",
      "280\n",
      "288\n",
      "296\n",
      "304\n",
      "312\n",
      "320\n",
      "328\n",
      "336\n",
      "344\n",
      "352\n",
      "360\n",
      "368\n",
      "376\n",
      "384\n",
      "392\n",
      "400\n",
      "408\n",
      "416\n",
      "424\n",
      "432\n",
      "440\n",
      "448\n",
      "456\n",
      "464\n",
      "472\n",
      "480\n",
      "488\n",
      "496\n",
      "504\n",
      "512\n",
      "520\n",
      "528\n",
      "536\n",
      "544\n",
      "552\n",
      "560\n",
      "568\n",
      "576\n",
      "584\n",
      "592\n",
      "600\n",
      "608\n",
      "616\n",
      "624\n",
      "632\n",
      "640\n",
      "648\n",
      "656\n",
      "664\n",
      "672\n",
      "680\n",
      "688\n",
      "696\n",
      "704\n",
      "712\n",
      "720\n",
      "728\n",
      "736\n",
      "744\n",
      "752\n",
      "760\n",
      "768\n",
      "776\n",
      "784\n",
      "792\n",
      "800\n",
      "808\n",
      "816\n",
      "824\n",
      "832\n",
      "840\n",
      "848\n",
      "856\n",
      "864\n",
      "872\n",
      "880\n",
      "888\n",
      "896\n",
      "904\n",
      "912\n",
      "920\n",
      "928\n",
      "936\n",
      "944\n",
      "952\n",
      "960\n",
      "968\n",
      "976\n",
      "984\n",
      "992\n",
      "1000\n",
      "1008\n",
      "1016\n",
      "1024\n",
      "1032\n",
      "1040\n",
      "1048\n",
      "1056\n",
      "1064\n",
      "1072\n",
      "1080\n",
      "1088\n",
      "1096\n",
      "1104\n",
      "1112\n",
      "1120\n",
      "1128\n",
      "1136\n",
      "1144\n",
      "1152\n",
      "1160\n",
      "1168\n",
      "1176\n",
      "1184\n",
      "1192\n",
      "1200\n",
      "1208\n",
      "1216\n",
      "1224\n",
      "1232\n",
      "1240\n",
      "1248\n",
      "1256\n",
      "1264\n",
      "1272\n",
      "1280\n",
      "1288\n",
      "1296\n",
      "1304\n",
      "1312\n",
      "1320\n",
      "1328\n",
      "1336\n",
      "1344\n",
      "1352\n",
      "1360\n",
      "1368\n",
      "1376\n",
      "1384\n",
      "1392\n",
      "1400\n",
      "1408\n",
      "1416\n",
      "1424\n",
      "1432\n",
      "1440\n",
      "1448\n",
      "1456\n",
      "1464\n",
      "1472\n",
      "1480\n",
      "1488\n",
      "1496\n",
      "1504\n",
      "1512\n",
      "1520\n",
      "1528\n",
      "1536\n",
      "1544\n",
      "1552\n",
      "1560\n",
      "1568\n",
      "1576\n",
      "1584\n",
      "1592\n",
      "1600\n",
      "1608\n",
      "1616\n",
      "1624\n",
      "1632\n",
      "1640\n",
      "1648\n",
      "1656\n",
      "1664\n",
      "1672\n",
      "1680\n",
      "1688\n",
      "1696\n",
      "1704\n",
      "1712\n",
      "1720\n",
      "1728\n",
      "1736\n",
      "1744\n",
      "1752\n",
      "1760\n",
      "1768\n",
      "1776\n",
      "1784\n",
      "1792\n",
      "1800\n",
      "1808\n",
      "1816\n",
      "1824\n",
      "1832\n",
      "1840\n",
      "1848\n",
      "1856\n",
      "1864\n",
      "1872\n",
      "1880\n",
      "1888\n",
      "1896\n",
      "1904\n",
      "1912\n",
      "1920\n",
      "1928\n",
      "1936\n",
      "1944\n",
      "1952\n",
      "1960\n",
      "1968\n",
      "1976\n",
      "1984\n",
      "1992\n",
      "2000\n",
      "2008\n",
      "2016\n",
      "2024\n",
      "2032\n",
      "2040\n",
      "2048\n",
      "2056\n",
      "2064\n",
      "2072\n",
      "2080\n",
      "2088\n",
      "2096\n",
      "2104\n",
      "2112\n",
      "2120\n",
      "2128\n",
      "2136\n",
      "2144\n",
      "2152\n",
      "2160\n",
      "2168\n",
      "2176\n",
      "2184\n",
      "2192\n",
      "2200\n",
      "2208\n",
      "2216\n",
      "2224\n",
      "2232\n",
      "2240\n",
      "2248\n",
      "2256\n",
      "2264\n",
      "2272\n",
      "2280\n",
      "2288\n",
      "2296\n",
      "2304\n",
      "2312\n",
      "2320\n",
      "2328\n",
      "2336\n",
      "2344\n",
      "2352\n",
      "2360\n",
      "2368\n",
      "2376\n",
      "2384\n",
      "2392\n",
      "2400\n",
      "2408\n",
      "2416\n",
      "2424\n",
      "2432\n",
      "2440\n",
      "2448\n",
      "2456\n",
      "2464\n",
      "2472\n",
      "2480\n",
      "2488\n",
      "2496\n",
      "2504\n",
      "2512\n",
      "2520\n",
      "2528\n",
      "2536\n",
      "2544\n",
      "2552\n",
      "2560\n",
      "2568\n",
      "2576\n",
      "2584\n",
      "2592\n",
      "2600\n",
      "2608\n",
      "2616\n",
      "2624\n",
      "2632\n",
      "2640\n",
      "2648\n",
      "2656\n",
      "2664\n",
      "2672\n",
      "2680\n",
      "2688\n",
      "2696\n",
      "2704\n",
      "2712\n",
      "2720\n",
      "2728\n",
      "2736\n",
      "2744\n",
      "2752\n",
      "2760\n",
      "2768\n",
      "2776\n",
      "2784\n",
      "2792\n",
      "2800\n",
      "2808\n",
      "2816\n",
      "2824\n",
      "2832\n",
      "2840\n",
      "2848\n",
      "2856\n",
      "2864\n",
      "2872\n",
      "2880\n",
      "2888\n",
      "2896\n",
      "2904\n",
      "2912\n",
      "2920\n",
      "2928\n",
      "2936\n",
      "2944\n",
      "2952\n",
      "2960\n",
      "2968\n",
      "2976\n",
      "2984\n",
      "2992\n",
      "3000\n",
      "3008\n",
      "3016\n",
      "3024\n",
      "3032\n",
      "3040\n",
      "3048\n",
      "3056\n",
      "3064\n",
      "3072\n",
      "3080\n",
      "3088\n",
      "3096\n",
      "3104\n",
      "3112\n",
      "3120\n",
      "3128\n",
      "3136\n",
      "3144\n",
      "3152\n",
      "3160\n",
      "3168\n",
      "3176\n",
      "3184\n",
      "3192\n",
      "3200\n",
      "3208\n",
      "3216\n",
      "3224\n",
      "3232\n",
      "3240\n",
      "3248\n",
      "3256\n",
      "3264\n",
      "3272\n",
      "3280\n",
      "3288\n",
      "3296\n",
      "3304\n",
      "3312\n",
      "3320\n",
      "3328\n",
      "3336\n",
      "3344\n",
      "3352\n",
      "3360\n",
      "3368\n",
      "3376\n",
      "3384\n",
      "3392\n",
      "3400\n",
      "3408\n",
      "3416\n",
      "3424\n",
      "3432\n",
      "3440\n",
      "3448\n",
      "3456\n",
      "3464\n",
      "3472\n",
      "3480\n",
      "3488\n",
      "3496\n",
      "3504\n",
      "3512\n",
      "3520\n",
      "3528\n",
      "3536\n",
      "3544\n",
      "3552\n",
      "3560\n",
      "3568\n",
      "3576\n",
      "3584\n",
      "3592\n",
      "3600\n",
      "3608\n",
      "3616\n",
      "3624\n",
      "3632\n",
      "3640\n",
      "3648\n",
      "3656\n",
      "3664\n",
      "3672\n",
      "3680\n",
      "3688\n",
      "3696\n",
      "3704\n",
      "3712\n",
      "3720\n",
      "3728\n",
      "3736\n",
      "3744\n",
      "3752\n",
      "3760\n",
      "3768\n",
      "3776\n",
      "3784\n",
      "3792\n",
      "3800\n",
      "3808\n",
      "3816\n",
      "3824\n",
      "3832\n",
      "3840\n",
      "3848\n",
      "3856\n",
      "3864\n",
      "3872\n",
      "3880\n",
      "3888\n",
      "3896\n",
      "3904\n",
      "3912\n",
      "3920\n",
      "3928\n",
      "3936\n",
      "3944\n",
      "3952\n",
      "3960\n",
      "3968\n",
      "3976\n",
      "3984\n",
      "3992\n",
      "4000\n",
      "4008\n",
      "4016\n",
      "4024\n",
      "4032\n",
      "4040\n",
      "4048\n",
      "4056\n",
      "4064\n",
      "4072\n",
      "4080\n",
      "4088\n",
      "4096\n",
      "4104\n",
      "4112\n",
      "4120\n",
      "4128\n",
      "4136\n",
      "4144\n",
      "4152\n",
      "4160\n",
      "4168\n",
      "4176\n",
      "4184\n",
      "4192\n",
      "4200\n",
      "4208\n",
      "4216\n",
      "4224\n",
      "4232\n",
      "4240\n",
      "4248\n",
      "4256\n",
      "4264\n",
      "4272\n",
      "4280\n",
      "4288\n",
      "4296\n",
      "4304\n",
      "4312\n",
      "4320\n",
      "4328\n",
      "4336\n",
      "4344\n",
      "4352\n",
      "4360\n",
      "4368\n",
      "4376\n",
      "4384\n",
      "4392\n",
      "4400\n",
      "4408\n",
      "4416\n",
      "4424\n",
      "4432\n",
      "4440\n",
      "4448\n",
      "4456\n",
      "4464\n",
      "4472\n",
      "4480\n",
      "4488\n",
      "4496\n",
      "4504\n",
      "4512\n",
      "4520\n",
      "4528\n",
      "4536\n",
      "4544\n",
      "4552\n",
      "4560\n",
      "4568\n",
      "4576\n",
      "4584\n",
      "4592\n",
      "4600\n",
      "4608\n",
      "4616\n",
      "4624\n",
      "4632\n",
      "4640\n",
      "4648\n",
      "4656\n",
      "4664\n",
      "4672\n",
      "4680\n",
      "4688\n",
      "4696\n",
      "4704\n",
      "4712\n",
      "4720\n",
      "4728\n",
      "4736\n",
      "4744\n",
      "4752\n",
      "4760\n",
      "4768\n",
      "4776\n",
      "4784\n",
      "4792\n",
      "4800\n",
      "4808\n",
      "4816\n",
      "4824\n",
      "4832\n",
      "4840\n",
      "4848\n",
      "4856\n",
      "4864\n",
      "4872\n",
      "4880\n",
      "4888\n",
      "4896\n",
      "4904\n",
      "4912\n",
      "4920\n",
      "4928\n",
      "4936\n",
      "4944\n",
      "4952\n",
      "4960\n",
      "4968\n",
      "4976\n",
      "4984\n",
      "4992\n",
      "5000\n",
      "5008\n",
      "5016\n",
      "5024\n",
      "5032\n",
      "5040\n",
      "5048\n",
      "5056\n",
      "5064\n",
      "5072\n",
      "5080\n",
      "5088\n",
      "5096\n",
      "5104\n",
      "5112\n",
      "5120\n",
      "5128\n",
      "5136\n",
      "5144\n",
      "5152\n",
      "5160\n",
      "5168\n",
      "5176\n",
      "5184\n",
      "5192\n",
      "5200\n",
      "5208\n",
      "5216\n",
      "5224\n",
      "5232\n",
      "5240\n",
      "5248\n",
      "5256\n",
      "5264\n",
      "5272\n",
      "5280\n",
      "5288\n",
      "5296\n",
      "5304\n",
      "5312\n",
      "5320\n",
      "5328\n",
      "5336\n",
      "5344\n",
      "5352\n",
      "5360\n",
      "5368\n",
      "5376\n",
      "5384\n",
      "5392\n",
      "5400\n",
      "5408\n",
      "5416\n",
      "5424\n",
      "5432\n",
      "5440\n",
      "5448\n",
      "5456\n",
      "5464\n",
      "5472\n",
      "5480\n",
      "5488\n",
      "5496\n",
      "5504\n",
      "5512\n",
      "5520\n",
      "5528\n",
      "5536\n",
      "5544\n",
      "5552\n",
      "5560\n",
      "5568\n",
      "5576\n",
      "5584\n",
      "5592\n",
      "5600\n",
      "5608\n",
      "5616\n",
      "5624\n",
      "5632\n",
      "5640\n",
      "5648\n",
      "5656\n",
      "5664\n",
      "5672\n",
      "5680\n",
      "5688\n",
      "5696\n",
      "5704\n",
      "5712\n",
      "5720\n",
      "5728\n",
      "5736\n",
      "5744\n",
      "5752\n",
      "5760\n",
      "5768\n",
      "5776\n",
      "5784\n",
      "5792\n",
      "5800\n",
      "5808\n",
      "5816\n",
      "5824\n",
      "5832\n",
      "5840\n",
      "5848\n",
      "5856\n",
      "5864\n",
      "5872\n",
      "5880\n",
      "5888\n",
      "5896\n",
      "5904\n",
      "5912\n",
      "5920\n",
      "5928\n",
      "5936\n",
      "5944\n",
      "5952\n",
      "5960\n",
      "5968\n",
      "5976\n",
      "5984\n",
      "5992\n",
      "6000\n",
      "6008\n",
      "6016\n",
      "6024\n",
      "6032\n",
      "6040\n",
      "6048\n",
      "6056\n",
      "6064\n",
      "6072\n",
      "6080\n",
      "6088\n",
      "6096\n",
      "6104\n",
      "6112\n",
      "6120\n",
      "6128\n",
      "6136\n",
      "6144\n",
      "6152\n",
      "6160\n",
      "6168\n",
      "6176\n",
      "6184\n",
      "6192\n",
      "6200\n",
      "6208\n",
      "6216\n",
      "6224\n",
      "6232\n",
      "6240\n",
      "6248\n",
      "6256\n",
      "6264\n",
      "6272\n",
      "6280\n",
      "6288\n",
      "6296\n",
      "6304\n",
      "6312\n",
      "6320\n",
      "6328\n",
      "6336\n",
      "6344\n",
      "6352\n",
      "6360\n",
      "6368\n",
      "6376\n",
      "6384\n",
      "6392\n",
      "6400\n",
      "6408\n",
      "6416\n",
      "6424\n",
      "6432\n",
      "6440\n",
      "6448\n",
      "6456\n",
      "6464\n",
      "6472\n",
      "6480\n",
      "6488\n",
      "6496\n",
      "6504\n",
      "6512\n",
      "6520\n",
      "6528\n",
      "6536\n",
      "6544\n",
      "6552\n",
      "6560\n",
      "6568\n",
      "6576\n",
      "6584\n",
      "6592\n",
      "6600\n",
      "6608\n",
      "6616\n",
      "6624\n",
      "6632\n",
      "6640\n",
      "6648\n",
      "6656\n",
      "6664\n",
      "6672\n",
      "6680\n",
      "6688\n",
      "6696\n",
      "6704\n",
      "6712\n",
      "6720\n",
      "6728\n",
      "6736\n",
      "6744\n",
      "6752\n",
      "6760\n",
      "6768\n",
      "6776\n",
      "6784\n",
      "6792\n",
      "6800\n",
      "6808\n",
      "6816\n",
      "6824\n",
      "6832\n",
      "6840\n",
      "6848\n",
      "6856\n",
      "6864\n",
      "6872\n",
      "6880\n",
      "6888\n",
      "6896\n",
      "6904\n",
      "6912\n",
      "6920\n",
      "6928\n",
      "6936\n",
      "6944\n",
      "6952\n",
      "6960\n",
      "6968\n",
      "6976\n",
      "6984\n",
      "6992\n",
      "7000\n",
      "7008\n",
      "7016\n",
      "7024\n",
      "7032\n",
      "7040\n",
      "7048\n",
      "7056\n",
      "7064\n",
      "7072\n",
      "7080\n",
      "7088\n",
      "7096\n",
      "7104\n",
      "7112\n",
      "7120\n",
      "7128\n",
      "7136\n",
      "7144\n",
      "7152\n",
      "7160\n",
      "7168\n",
      "7176\n",
      "7184\n",
      "7192\n",
      "7200\n",
      "7208\n",
      "7216\n",
      "7224\n",
      "7232\n",
      "7240\n",
      "7248\n",
      "7256\n",
      "7264\n",
      "7272\n",
      "7280\n",
      "7288\n",
      "7296\n",
      "7304\n",
      "7312\n",
      "7320\n",
      "7328\n",
      "7336\n",
      "7344\n",
      "7352\n",
      "7360\n",
      "7368\n",
      "7376\n",
      "7384\n",
      "7392\n",
      "7400\n",
      "7408\n",
      "7416\n",
      "7424\n",
      "7432\n",
      "7440\n",
      "7448\n",
      "7456\n",
      "7464\n",
      "7472\n",
      "7480\n",
      "7488\n",
      "7496\n",
      "7504\n",
      "7512\n",
      "7520\n",
      "7528\n",
      "7536\n",
      "7544\n",
      "7552\n",
      "7560\n",
      "7568\n",
      "7576\n",
      "7584\n",
      "7592\n",
      "7600\n",
      "7608\n",
      "7616\n",
      "7624\n",
      "7632\n",
      "7640\n",
      "7648\n",
      "7656\n",
      "7664\n",
      "7672\n",
      "7680\n",
      "7688\n",
      "7696\n",
      "7704\n",
      "7712\n",
      "7720\n",
      "7728\n",
      "7736\n",
      "7744\n",
      "7752\n",
      "7760\n",
      "7768\n",
      "7776\n",
      "7784\n",
      "7792\n",
      "7800\n",
      "7808\n",
      "7816\n",
      "7824\n",
      "7832\n",
      "7840\n",
      "7848\n",
      "7856\n",
      "7864\n",
      "7872\n",
      "7880\n",
      "7888\n",
      "7896\n",
      "7904\n",
      "7912\n",
      "7920\n",
      "7928\n",
      "7936\n",
      "7944\n",
      "7952\n",
      "7960\n",
      "7968\n",
      "7976\n",
      "7984\n",
      "7992\n",
      "8000\n",
      "8008\n",
      "8016\n",
      "8024\n",
      "8032\n",
      "8040\n",
      "8048\n",
      "8056\n",
      "8064\n",
      "8072\n",
      "8080\n",
      "8088\n",
      "8096\n",
      "8104\n",
      "8112\n",
      "8120\n",
      "8128\n",
      "8136\n",
      "8144\n",
      "8152\n",
      "8160\n",
      "8168\n",
      "8176\n",
      "8184\n",
      "8192\n",
      "8200\n",
      "8208\n",
      "8216\n",
      "8224\n",
      "8232\n",
      "8240\n",
      "8248\n",
      "8256\n",
      "8264\n",
      "8272\n",
      "8280\n",
      "8288\n",
      "8296\n",
      "8304\n",
      "8312\n",
      "8320\n",
      "8328\n",
      "8336\n",
      "8344\n",
      "8352\n",
      "8360\n",
      "8368\n",
      "8376\n",
      "8384\n",
      "8392\n",
      "8400\n",
      "8408\n",
      "8416\n",
      "8424\n",
      "8432\n",
      "8440\n",
      "8448\n",
      "8456\n",
      "8464\n",
      "8472\n",
      "8480\n",
      "8488\n",
      "8496\n",
      "8504\n",
      "8512\n",
      "8520\n",
      "8528\n",
      "8536\n",
      "8544\n",
      "8552\n",
      "8560\n",
      "8568\n",
      "8576\n",
      "8584\n",
      "8592\n",
      "8600\n",
      "8608\n",
      "8616\n",
      "8624\n",
      "8632\n",
      "8640\n",
      "8648\n",
      "8656\n",
      "8664\n",
      "8672\n",
      "8680\n",
      "8688\n",
      "8696\n",
      "8704\n",
      "8712\n",
      "8720\n",
      "8728\n",
      "8736\n",
      "8744\n",
      "8752\n",
      "8760\n",
      "8768\n",
      "8776\n",
      "8784\n",
      "8792\n",
      "8800\n",
      "8808\n",
      "8816\n",
      "8824\n",
      "8832\n",
      "8840\n",
      "8848\n",
      "8856\n",
      "8864\n",
      "8872\n",
      "8880\n",
      "8888\n",
      "8896\n",
      "8904\n",
      "8912\n",
      "8920\n",
      "8928\n",
      "8936\n",
      "8944\n",
      "8952\n",
      "8960\n",
      "8968\n",
      "8976\n",
      "8984\n",
      "8992\n",
      "9000\n",
      "9008\n",
      "9016\n",
      "9024\n",
      "9032\n",
      "9040\n",
      "9048\n",
      "9056\n",
      "9064\n",
      "9072\n",
      "9080\n",
      "9088\n",
      "9096\n",
      "9104\n",
      "9112\n",
      "9120\n",
      "9128\n",
      "9136\n",
      "9144\n",
      "9152\n",
      "9160\n",
      "9168\n",
      "9176\n",
      "9184\n",
      "9192\n",
      "9200\n",
      "9208\n",
      "9216\n",
      "9224\n",
      "9232\n",
      "9240\n",
      "9248\n",
      "9256\n",
      "9264\n",
      "9272\n",
      "9280\n",
      "9288\n",
      "9296\n",
      "9304\n",
      "9312\n",
      "9320\n",
      "9328\n",
      "9336\n",
      "9344\n",
      "9352\n",
      "9360\n",
      "9368\n",
      "9376\n",
      "9384\n",
      "9392\n",
      "9400\n",
      "9408\n",
      "9416\n",
      "9424\n",
      "9432\n",
      "9440\n",
      "9448\n",
      "9456\n",
      "9464\n",
      "9472\n",
      "9480\n",
      "9488\n",
      "9496\n",
      "9504\n",
      "9512\n",
      "9520\n",
      "9528\n",
      "9536\n",
      "9544\n",
      "9552\n",
      "9560\n",
      "9568\n",
      "9576\n",
      "9584\n",
      "9592\n",
      "9600\n",
      "9608\n",
      "9616\n",
      "9624\n",
      "9632\n",
      "9640\n",
      "9648\n",
      "9656\n",
      "9664\n",
      "9672\n",
      "9680\n",
      "9688\n",
      "9696\n",
      "9704\n",
      "9712\n",
      "9720\n",
      "9728\n",
      "9736\n",
      "9744\n",
      "9752\n",
      "9760\n",
      "9768\n",
      "9776\n",
      "9784\n",
      "9792\n",
      "9800\n",
      "9808\n",
      "9816\n",
      "9824\n",
      "9832\n",
      "9840\n",
      "9848\n",
      "9856\n",
      "9864\n",
      "9872\n",
      "9880\n",
      "9888\n",
      "9896\n",
      "9904\n",
      "9912\n",
      "9920\n",
      "9928\n",
      "9936\n",
      "9944\n",
      "9952\n",
      "9960\n",
      "9968\n",
      "9976\n",
      "9984\n",
      "9992\n",
      "10000\n",
      "10008\n",
      "10016\n",
      "10024\n",
      "10032\n",
      "10040\n",
      "10048\n",
      "10056\n",
      "10064\n",
      "10072\n",
      "10080\n",
      "10088\n",
      "10096\n",
      "10104\n",
      "10112\n",
      "10120\n",
      "10128\n",
      "10136\n",
      "10144\n",
      "10152\n",
      "10160\n",
      "10168\n",
      "10176\n",
      "10184\n",
      "10192\n",
      "10200\n",
      "10208\n",
      "10216\n",
      "10224\n",
      "10232\n",
      "10240\n",
      "10248\n",
      "10256\n",
      "10264\n",
      "10272\n",
      "10280\n",
      "10288\n",
      "10290\n",
      "8\n",
      "16\n",
      "24\n",
      "32\n",
      "40\n",
      "48\n",
      "56\n",
      "64\n",
      "72\n",
      "80\n",
      "88\n",
      "96\n",
      "104\n",
      "112\n",
      "120\n",
      "128\n",
      "136\n",
      "144\n",
      "152\n",
      "160\n",
      "168\n",
      "176\n",
      "184\n",
      "192\n",
      "200\n",
      "208\n",
      "216\n",
      "224\n",
      "232\n",
      "240\n",
      "248\n",
      "256\n",
      "264\n",
      "272\n",
      "280\n",
      "288\n",
      "296\n",
      "304\n",
      "312\n",
      "320\n",
      "328\n",
      "336\n",
      "344\n",
      "352\n",
      "360\n",
      "368\n",
      "376\n",
      "384\n",
      "392\n",
      "400\n",
      "408\n",
      "416\n",
      "424\n",
      "432\n",
      "440\n",
      "448\n",
      "456\n",
      "464\n",
      "472\n",
      "480\n",
      "488\n",
      "496\n",
      "504\n",
      "512\n",
      "520\n",
      "528\n",
      "536\n",
      "544\n",
      "552\n",
      "560\n",
      "568\n",
      "576\n",
      "584\n",
      "592\n",
      "600\n",
      "608\n",
      "616\n",
      "624\n",
      "632\n",
      "640\n",
      "648\n",
      "656\n",
      "664\n",
      "672\n",
      "680\n",
      "688\n",
      "696\n",
      "704\n",
      "712\n",
      "720\n",
      "728\n",
      "736\n",
      "744\n",
      "752\n",
      "760\n",
      "768\n",
      "776\n",
      "784\n",
      "792\n",
      "800\n",
      "808\n",
      "816\n",
      "824\n",
      "832\n",
      "840\n",
      "848\n",
      "856\n",
      "864\n",
      "872\n",
      "880\n",
      "888\n",
      "896\n",
      "904\n",
      "912\n",
      "920\n",
      "928\n",
      "936\n",
      "944\n",
      "952\n",
      "960\n",
      "968\n",
      "976\n",
      "984\n",
      "992\n",
      "1000\n",
      "1008\n",
      "1016\n",
      "1024\n",
      "1032\n",
      "1040\n",
      "1048\n",
      "1056\n",
      "1064\n",
      "1072\n",
      "1080\n",
      "1088\n",
      "1096\n",
      "1104\n",
      "1112\n",
      "1120\n",
      "1128\n",
      "1136\n",
      "1144\n",
      "1152\n",
      "1160\n",
      "1168\n",
      "1176\n",
      "1184\n",
      "1192\n",
      "1200\n",
      "1208\n",
      "1216\n",
      "1224\n",
      "1232\n",
      "1240\n",
      "1248\n",
      "1256\n",
      "1264\n",
      "1272\n",
      "1280\n",
      "1288\n",
      "1296\n",
      "1304\n",
      "1312\n",
      "1320\n",
      "1328\n",
      "1336\n",
      "1344\n",
      "1352\n",
      "1360\n",
      "1368\n",
      "1376\n",
      "1384\n",
      "1392\n",
      "1400\n",
      "1408\n",
      "1416\n",
      "1424\n",
      "1432\n",
      "1440\n",
      "1448\n",
      "1456\n",
      "1464\n",
      "1472\n",
      "1480\n",
      "1488\n",
      "1496\n",
      "1504\n",
      "1512\n",
      "1520\n",
      "1528\n",
      "1536\n",
      "1544\n",
      "1552\n",
      "1560\n",
      "1568\n",
      "1576\n",
      "1584\n",
      "1592\n",
      "1600\n",
      "1608\n",
      "1616\n",
      "1624\n",
      "1632\n",
      "1640\n",
      "1648\n",
      "1656\n",
      "1664\n",
      "1672\n",
      "1680\n",
      "1688\n",
      "1696\n",
      "1704\n",
      "1712\n",
      "1720\n",
      "1728\n",
      "1736\n",
      "1744\n",
      "1752\n",
      "1760\n",
      "1768\n",
      "1776\n",
      "1784\n",
      "1792\n",
      "1800\n",
      "1808\n",
      "1816\n",
      "1824\n",
      "1832\n",
      "1840\n",
      "1848\n",
      "1856\n",
      "1864\n",
      "1872\n",
      "1880\n",
      "1888\n",
      "1896\n",
      "1904\n",
      "1912\n",
      "1920\n",
      "1928\n",
      "1936\n",
      "1944\n",
      "1952\n",
      "1960\n",
      "1968\n",
      "1976\n",
      "1984\n",
      "1992\n",
      "2000\n",
      "2008\n",
      "2016\n",
      "2024\n",
      "2032\n",
      "2040\n",
      "2048\n",
      "2056\n",
      "2064\n",
      "2072\n",
      "2080\n",
      "2088\n",
      "2096\n",
      "2104\n",
      "2112\n",
      "2120\n",
      "2128\n",
      "2136\n",
      "2144\n",
      "2152\n",
      "2160\n",
      "2168\n",
      "2176\n",
      "2184\n",
      "2192\n",
      "2200\n",
      "2208\n",
      "2216\n",
      "2224\n",
      "2232\n",
      "2240\n",
      "2248\n",
      "2256\n",
      "2264\n",
      "2272\n",
      "2280\n",
      "2288\n",
      "2296\n",
      "2304\n",
      "2312\n",
      "2320\n",
      "2328\n",
      "2336\n",
      "2344\n",
      "2352\n",
      "2360\n",
      "2368\n",
      "2376\n",
      "2384\n",
      "2392\n",
      "2400\n",
      "2408\n",
      "2416\n",
      "2424\n",
      "2432\n",
      "2440\n",
      "2448\n",
      "2456\n",
      "2464\n",
      "2472\n",
      "2480\n",
      "2488\n",
      "2496\n",
      "2504\n",
      "2512\n",
      "2520\n",
      "2528\n",
      "2536\n",
      "2544\n",
      "2552\n",
      "2560\n",
      "2568\n",
      "2576\n",
      "2584\n",
      "2592\n",
      "2600\n",
      "2608\n",
      "2616\n",
      "2624\n",
      "2632\n",
      "2640\n",
      "2648\n",
      "2656\n",
      "2664\n",
      "2672\n",
      "2680\n",
      "2688\n",
      "2696\n",
      "2704\n",
      "2712\n",
      "2720\n",
      "2728\n",
      "2736\n",
      "2744\n",
      "2752\n",
      "2760\n",
      "2768\n",
      "2776\n",
      "2784\n",
      "2792\n",
      "2800\n",
      "2808\n",
      "2816\n",
      "2824\n",
      "2825\n",
      "torch.Size([2825, 6656])\n",
      "Rank@1:0.909027 Rank@5:0.961770 Rank@10:0.974867 mAP:0.785483\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# Options\n",
    "# --------\n",
    "gpu_ids = '0'\n",
    "which_epoch = 70\n",
    "test_dir = r'C:\\Users\\reID\\Desktop\\Market\\pytorch'\n",
    "name = 'ft_net_v7'\n",
    "batchsize = 8\n",
    "\n",
    "str_ids = gpu_ids.split(',')\n",
    "\n",
    "test_dir = test_dir\n",
    "\n",
    "gpu_ids = []\n",
    "for str_id in str_ids:\n",
    "    id = int(str_id)\n",
    "    if id >=0:\n",
    "        gpu_ids.append(id)\n",
    "\n",
    "# set gpu ids\n",
    "if len(gpu_ids)>0:\n",
    "    torch.cuda.set_device(gpu_ids[0])\n",
    "\n",
    "######################################################################\n",
    "# Load Data\n",
    "# ---------\n",
    "#\n",
    "# We will use torchvision and torch.utils.data packages for loading the\n",
    "# data.\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((256,128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_dir = test_dir\n",
    "image_datasets = {x: datasets.ImageFolder( os.path.join(data_dir,x) ,data_transforms) for x in ['gallery','query']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size= batchsize,\n",
    "                                             shuffle=False, num_workers=8) for x in ['gallery','query']}\n",
    "class_names = image_datasets['query'].classes\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "######################################################################\n",
    "# Load model\n",
    "#---------------------------\n",
    "def load_network(network):\n",
    "    save_path = os.path.join('./model',name,'net_%s.pth'%which_epoch)\n",
    "    network.load_state_dict(torch.load(save_path))\n",
    "    return network\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Extract feature\n",
    "# ----------------------\n",
    "def fliplr(img):\n",
    "    '''flip horizontal'''\n",
    "    inv_idx = torch.arange(img.size(3)-1,-1,-1).long()  # N x C x H x W\n",
    "    img_flip = img.index_select(3,inv_idx)\n",
    "    return img_flip\n",
    "\n",
    "def extract_feature(model,dataloaders):\n",
    "    features = torch.FloatTensor()\n",
    "    count = 0\n",
    "    for data in dataloaders:\n",
    "        img, label = data\n",
    "        n, c, h, w = img.size()\n",
    "        count += n\n",
    "        print(count)\n",
    "        ff = torch.FloatTensor(n,6656).zero_()\n",
    "        for i in range(2):\n",
    "            if(i==1):\n",
    "                img = fliplr(img)\n",
    "            input_img = Variable(img.cuda())\n",
    "            #img=img.unsqueeze(0)outputs_4\n",
    "            \n",
    "            outputs= model(input_img)\n",
    "            f = outputs.data.cpu()\n",
    "            ff = ff+f\n",
    "        # norm feature\n",
    "       \n",
    "        \n",
    "        fnorm = torch.norm(ff, p=2, dim=1, keepdim=True)\n",
    "        ff = ff.div(fnorm.expand_as(ff))\n",
    "\n",
    "        features = torch.cat((features,ff), 0)\n",
    "    return features\n",
    "\n",
    "def get_id(img_path):\n",
    "    camera_id = []\n",
    "    labels = []\n",
    "    for path, v in img_path:\n",
    "        #filename = path.split('/')[-1]\n",
    "        filename = os.path.basename(path)\n",
    "        label = filename[0:5]\n",
    "        #label=filename[0:4]\n",
    "        camera = filename.split('_')[2]\n",
    "        if label[0:2]=='-1':\n",
    "            labels.append(-1)\n",
    "        else:\n",
    "            labels.append(int(label))\n",
    "        camera_id.append(int(camera[0]))\n",
    "    return camera_id, labels\n",
    "\n",
    "gallery_path = image_datasets['gallery'].imgs\n",
    "query_path = image_datasets['query'].imgs\n",
    "\n",
    "gallery_cam,gallery_label = get_id(gallery_path)\n",
    "query_cam,query_label = get_id(query_path)\n",
    "\n",
    "######################################################################\n",
    "# Load Collected data Trained model\n",
    "print('-------test-----------')\n",
    "#model_structure =ft_net_middle(751)\n",
    "#model_structure = ft_net_50_1(751)\n",
    "model_structure = get_cls_net(False, config)\n",
    "model = load_network(model_structure)\n",
    "\n",
    "model = model.eval()\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "# Extract feature\n",
    "gallery_feature = extract_feature(model,dataloaders['gallery'])\n",
    "query_feature = extract_feature(model,dataloaders['query'])\n",
    "\n",
    "    \n",
    "# Save to Matlab for check\n",
    "result = {'gallery_f':gallery_feature.numpy(),'gallery_label':gallery_label,'gallery_cam':gallery_cam,'query_f':query_feature.numpy(),'query_label':query_label,'query_cam':query_cam}\n",
    "scipy.io.savemat('pytorch_result.mat',result)\n",
    "\n",
    "#######################################################################\n",
    "# Evaluate\n",
    "def evaluate(qf,ql,qc,gf,gl,gc):\n",
    "    query = qf.view(-1,1)\n",
    "    # print(query.shape)\n",
    "    score = torch.mm(gf,query)\n",
    "    score = score.squeeze(1).cpu()\n",
    "    score = score.numpy()\n",
    "    # predict index\n",
    "    index = np.argsort(score)  #from small to large\n",
    "    index = index[::-1]\n",
    "    # index = index[0:2000]\n",
    "    # good index\n",
    "    query_index = np.argwhere(gl==ql)\n",
    "    camera_index = np.argwhere(gc==qc)\n",
    "\n",
    "    good_index = np.setdiff1d(query_index, camera_index, assume_unique=True)\n",
    "    junk_index1 = np.argwhere(gl==-1)\n",
    "    junk_index2 = np.intersect1d(query_index, camera_index)\n",
    "    junk_index = np.append(junk_index2, junk_index1) #.flatten())\n",
    "    \n",
    "    CMC_tmp = compute_mAP(index, good_index, junk_index)\n",
    "    return CMC_tmp\n",
    "\n",
    "\n",
    "def compute_mAP(index, good_index, junk_index):\n",
    "    ap = 0\n",
    "    cmc = torch.IntTensor(len(index)).zero_()\n",
    "    if good_index.size==0:   # if empty\n",
    "        cmc[0] = -1\n",
    "        return ap,cmc\n",
    "\n",
    "    # remove junk_index\n",
    "    mask = np.in1d(index, junk_index, invert=True)\n",
    "    index = index[mask]\n",
    "\n",
    "    # find good_index index\n",
    "    ngood = len(good_index)\n",
    "    mask = np.in1d(index, good_index)\n",
    "    rows_good = np.argwhere(mask==True)\n",
    "    rows_good = rows_good.flatten()\n",
    "    \n",
    "    cmc[rows_good[0]:] = 1\n",
    "    for i in range(ngood):\n",
    "        d_recall = 1.0/ngood\n",
    "        precision = (i+1)*1.0/(rows_good[i]+1)\n",
    "        if rows_good[i]!=0:\n",
    "            old_precision = i*1.0/rows_good[i]\n",
    "        else:\n",
    "            old_precision=1.0\n",
    "        ap = ap + d_recall*(old_precision + precision)/2\n",
    "\n",
    "    return ap, cmc\n",
    "\n",
    "######################################################################\n",
    "result = scipy.io.loadmat('pytorch_result.mat')\n",
    "query_feature = torch.FloatTensor(result['query_f'])\n",
    "query_cam = result['query_cam'][0]\n",
    "query_label = result['query_label'][0]\n",
    "gallery_feature = torch.FloatTensor(result['gallery_f'])\n",
    "gallery_cam = result['gallery_cam'][0]\n",
    "gallery_label = result['gallery_label'][0]\n",
    "\n",
    "multi = os.path.isfile('multi_query.mat')\n",
    "\n",
    "if multi:\n",
    "    m_result = scipy.io.loadmat('multi_query.mat')\n",
    "    mquery_feature = torch.FloatTensor(m_result['mquery_f'])\n",
    "    mquery_cam = m_result['mquery_cam'][0]\n",
    "    mquery_label = m_result['mquery_label'][0]\n",
    "    mquery_feature = mquery_feature.cuda()\n",
    "\n",
    "query_feature = query_feature.cuda()\n",
    "gallery_feature = gallery_feature.cuda()\n",
    "\n",
    "print(query_feature.shape)\n",
    "CMC = torch.IntTensor(len(gallery_label)).zero_()\n",
    "ap = 0.0\n",
    "#print(query_label)\n",
    "for i in range(len(query_label)):\n",
    "    ap_tmp, CMC_tmp = evaluate(query_feature[i],query_label[i],query_cam[i],gallery_feature,gallery_label,gallery_cam)\n",
    "    if CMC_tmp[0]==-1:\n",
    "        continue\n",
    "    CMC = CMC + CMC_tmp\n",
    "    ap += ap_tmp\n",
    "    #print(i, CMC_tmp[0])\n",
    "\n",
    "CMC = CMC.float()\n",
    "CMC = CMC/len(query_label) #average CMC\n",
    "print('Rank@1:%f Rank@5:%f Rank@10:%f mAP:%f'%(CMC[0],CMC[4],CMC[9],ap/len(query_label)))\n",
    "name = 'ft_net'\n",
    "\n",
    "# multiple-query\n",
    "CMC = torch.IntTensor(len(gallery_label)).zero_()\n",
    "ap = 0.0\n",
    "if multi:\n",
    "    for i in range(len(query_label)):\n",
    "        mquery_index1 = np.argwhere(mquery_label==query_label[i])\n",
    "        mquery_index2 = np.argwhere(mquery_cam==query_cam[i])\n",
    "        mquery_index =  np.intersect1d(mquery_index1, mquery_index2)\n",
    "        mq = torch.mean(mquery_feature[mquery_index,:], dim=0)\n",
    "        ap_tmp, CMC_tmp = evaluate(mq,query_label[i],query_cam[i],gallery_feature,gallery_label,gallery_cam)\n",
    "        if CMC_tmp[0]==-1:\n",
    "            continue\n",
    "        CMC = CMC + CMC_tmp\n",
    "        ap += ap_tmp\n",
    "        #print(i, CMC_tmp[0])\n",
    "    CMC = CMC.float()\n",
    "    CMC = CMC/len(query_label) #average CMC\n",
    "    print('multi Rank@1:%f Rank@5:%f Rank@10:%f mAP:%f'%(CMC[0],CMC[4],CMC[9],ap/len(query_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1_5",
   "language": "python",
   "name": "pytorch1_5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
